{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE_assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "xxdvrRVPYEbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, UpSampling2D, MaxPool2D, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W7s4l1GBTQ3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_reshape(x):\n",
        "  x = x.reshape(-1, 28, 28, 1)\n",
        "  x = x.astype('float32') / 255\n",
        "  x_flatten = x.reshape((len(x), np.prod(x_train.shape[1:])))\n",
        "  \n",
        "  return x, x_flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hMsXaVuBfxEu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_mlp_ae(encoding_dim):\n",
        "  input_img = Input(shape=(784,))\n",
        "\n",
        "  # \"encoded\" is the encoded representation of the input\n",
        "  encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "\n",
        "  # \"decoded\" is the lossy reconstruction of the input\n",
        "  decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "  # this model maps an input to its reconstruction\n",
        "  autoencoder = Model(input_img, decoded)\n",
        "\n",
        "  encoder = Model(input_img, encoded)\n",
        "\n",
        "  # create a placeholder for an encoded (32-dimensional) input\n",
        "  encoded_input = Input(shape=(encoding_dim,))\n",
        "  # retrieve the last layer of the autoencoder model\n",
        "  decoder_layer = autoencoder.layers[-1]\n",
        "  # create the decoder model\n",
        "  decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "  \n",
        "  return encoder, decoder, autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qwOP7z5Gg4Mm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_cnn_ae():\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cDRTL-bhE5Qv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_sample(imgs, encoded_imgs, encoded_imgs_size, decoded_imgs):\n",
        "  ids = np.random.randint(10000, size=10)\n",
        "  for id in ids:\n",
        "    plt.figure(figsize=(10, 12))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(imgs[id].reshape([-1, 28]))\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(encoded_imgs[id].reshape([-1, encoded_imgs_size]))\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(decoded_imgs[id].reshape([-1, 28]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9g-MHMIzgOOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(x_train_mnist, _), (x_test_mnist, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train, x_train_flatten = normalize_reshape(x_train)\n",
        "x_test, x_test_flatten = normalize_reshape(x_test)\n",
        "\n",
        "x_train_mnist, x_train_mnist_flatten = normalize_reshape(x_train_mnist)\n",
        "x_test_mnist, x_test_mnist_flatten = normalize_reshape(x_test_mnist)\n",
        "\n",
        "e, d, ae = get_mlp_ae(64)\n",
        "ae.compile(optimizer='adadelta', loss='mse')\n",
        "ae.fit(x_train_flatten, x_train_flatten,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_flatten, x_test_flatten))\n",
        "\n",
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = e.predict(x_test_flatten)\n",
        "decoded_imgs = d.predict(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIbs5ECbZEvH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_sample(x_test, encoded_imgs, 8, decoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBjdHzQADidI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "e_mnist, d_mnist, ae_mnist = get_mlp_ae(64)\n",
        "ae_mnist.compile(optimizer='adadelta', loss='mse')\n",
        "ae_mnist.fit(x_train_mnist_flatten, x_train_mnist_flatten,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_mnist_flatten, x_test_mnist_flatten))\n",
        "\n",
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs_mnist = e_mnist.predict(x_test_mnist_flatten)\n",
        "decoded_imgs_mnist = d_mnist.predict(encoded_imgs_mnist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yglbavTFRU9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_sample(x_test_mnist_flatten, encoded_imgs_mnist, 8, decoded_imgs_mnist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4nvWqcOEeO5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded_imgs_1 = e_mnist.predict(x_test_flatten)\n",
        "decoded_imgs_1 = d_mnist.predict(encoded_imgs_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6UulOoZaE8bQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_sample(x_test_flatten, encoded_imgs_1, 8, decoded_imgs_1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}